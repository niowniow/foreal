# Potential Use Cases
There are several advantages using a declarative data access model:

- **Flexibility** Selecting the required data segments from a dataset is facilitated, since complex data loading and processing is abstracted.
- **Inter-dependencies** If there is a dependency of a successive task on its predecessors the declarative paradigm gives the successive task the option to declare these dependencies. Examples are the dependency of spectrogram input to its parameters or a machine learning model which requires a specific set of parametrization for its inputs.
- **Data augmentation** Declarative data access can be used for controlled randomization. Each parameter can be defined and stored on a per-sample basis, which allows perfect replay and per-sample optimization of data augmentation parameters.
- **Dynamic sample merging** Deep learning for audio applications benefits from superposition of multiple audio segments during training. For example merging two segments of the same label create a new, unseen segment while retaining the correct label. Declarative data access facilitates the process because a second segment of the same label can be explicitly requested during runtime.
- **Dynamic zoom** Signal processing algorithms usually scale with input size, meaning if we process an image, the runtime is dependant on the image dimensions. In Chapter~\ref{ch:IdentifyingInfluences} we avoid large processing costs by downscaling the images before applying an image classifier. However, small features are indistinguishable in low-resolution images. Zooming in on details could reveal more information but only if zooming results in a higher resolution segment of the image. With declarative data access we could make the resolution dependent on the zoom level - keeping the image dimension constant while the resolution scales.
- **Access to expanding datasets** Continuous data acquisition requires certain computations to be run every time new data arrives. Declarative data access avoids these time-triggered computations because when the data is accessed the computations will be run automatically.
- **Relabeling** During relabeling new annotations are added to the dataset or the existing annotations of a dataset are modified. If the declarative approach (for example requesting all annotations of a time segment) is used in combination with the data independence paradigm (annotations are abstract bounding boxes), the change in the annotation set is immediately reflected in any use case of the dataset (machine learning, visualization), which makes the different use cases consistent.
